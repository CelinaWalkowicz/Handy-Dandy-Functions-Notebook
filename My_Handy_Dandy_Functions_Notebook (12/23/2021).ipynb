{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "My Handy Dandy Functions Notebook",
      "provenance": [],
      "collapsed_sections": [
        "LVhaFLZf5Yd6"
      ],
      "authorship_tag": "ABX9TyPMH36V+/KWOHGXg0T504Qa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CelinaWalkowicz/Handy-Dandy-Functions-Notebook/blob/main/My_Handy_Dandy_Functions_Notebook%20(12/23/2021).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ad9OeRt5dUYK"
      },
      "source": [
        "\n",
        "#Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdBnLN4seB2t"
      },
      "source": [
        "def col_info(col):\n",
        "  ### This function returns column information ###\n",
        "  col_total = col.value_counts().sum()\n",
        "  col_Val_count = col.value_counts()\n",
        "  col_freq = col.value_counts(normalize=True)*100\n",
        "  col_unique = col.nunique()\n",
        "  col_describe = col.describe()\n",
        "\n",
        "  print(f\"\"\"\n",
        "There are {col_total} samples in {col_unique} cateogries.\n",
        "  \n",
        "Sample Count per Category:\n",
        "{col_Val_count}\n",
        "\n",
        "Sample Frequency per Category:\n",
        "{col_freq}\n",
        "\n",
        "Sample Statistical Data:\n",
        "{col_describe}\n",
        "\n",
        "  \"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hv-ZET7gEIa7"
      },
      "source": [
        "def val_counts(Data_Frame):\n",
        "    ## This function returns the value counts for ALL Columns in a DataFrame ##\n",
        "    for col in Data_Frame:\n",
        "      print(f'''\n",
        "      Feature: {col}\n",
        "      Counts:\n",
        "      {df[col].value_counts()}\n",
        "\n",
        "      ''')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVhaFLZf5Yd6"
      },
      "source": [
        "## Pandas Profiling\n",
        "*  This has replaced explore_df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4TijRK_5bT9"
      },
      "source": [
        "### THIS IS NOT A FUNCTION ###\n",
        "\n",
        "## PANDAS PROFILING ##\n",
        "\n",
        "# PIP INSTALL # \n",
        "\n",
        "!pip install pandas-profiling==2.7.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDTcq6-c5G62"
      },
      "source": [
        "### THIS IS NOT A FUNCTION ###\n",
        "\n",
        "## PANDAS PROFILING ##\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas_profiling import ProfileReport\n",
        "\n",
        "profile = ProfileReport(df)\n",
        "profile\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2uD6fmn5DnW"
      },
      "source": [
        "##Dead"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jw9zJhXqdXqf"
      },
      "source": [
        "def explore_df(Data_Frame):\n",
        "  ### This function finds exploratory information on the DataFrame, and Returns a Summary ###\n",
        "    # Explore\n",
        "  Data_Frame_head = Data_Frame.head()\n",
        "  Data_Frame_shape = Data_Frame.shape\n",
        "  Data_Frame_nulls = Data_Frame.isnull().sum()\n",
        "  Data_Frame_null_sum = Data_Frame.isnull().sum().sum()\n",
        "  Data_Frame_desc = Data_Frame.describe()\n",
        "  Data_Frame_info = Data_Frame.info()\n",
        "  Data_Frame_col_names = Data_Frame.columns\n",
        "    #Summary\n",
        "  print(f'''\n",
        "  \n",
        "Text Data Frame Exploration Values\n",
        "\n",
        "Shape: {Data_Frame_shape}\n",
        "\n",
        "Total Null Values: {Data_Frame_null_sum}\n",
        "Null Distribution:\n",
        "{Data_Frame_nulls}\n",
        "\n",
        "Data Statistical Summary:\n",
        "{Data_Frame_desc}\n",
        "''')\n",
        "  return Data_Frame_head"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sghEgEzR8XQz"
      },
      "source": [
        "#Wrangling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdGdtdaO7yt4"
      },
      "source": [
        "### This is scaffolding for a Dataframe with a DateTime Index ###\n",
        "##Remove Rows with Fill In Strings in the Pd.Read section for regular DF ##\n",
        "\n",
        "data_url = \n",
        "\n",
        "def wrangle(filepath):\n",
        "  ## This function performs all preliminary Data Wrangling in one go ##\n",
        "  df = pd.read_csv(filepath, \n",
        "                   parse_dates=[''],                                              #Fill In Strings\n",
        "                   index_col =[''])                                               #Fill In Strings\n",
        "                   \n",
        "  # Format Column Names\n",
        "  df.columns = df.columns.str.replace(' ','_')\n",
        "  df.columns = [x.lower() for x in df.columns]\n",
        "\n",
        "\n",
        "  return df\n",
        "\n",
        "df = wrangle(data_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFVLrdRC688r"
      },
      "source": [
        "### This is not a function ###\n",
        "\n",
        "## This For Loop Determines if Catergorical Columns are High Cardinality, and Drops Them ##\n",
        "\n",
        "# Threshold should be 60%, or > than 2200 for large data sets\n",
        "threshold = ## Insert ##\n",
        "cols_to_drop = []\n",
        "\n",
        "  for col in df:\n",
        "    if df[col].dtype == 'object':\n",
        "      if df[col].nunique() > threshold:\n",
        "        cols_to_drop.append(col)\n",
        "  \n",
        "  df.drop(columns=cols_to_drop, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rhiZfRBq8Hq"
      },
      "source": [
        "def drop_cat_cols(x):\n",
        "  ### This function drops Categorical Columns ###\n",
        "  for col in df:\n",
        "    if df[col].dtype == 'object':\n",
        "      df.drop(columns=col, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71HlyEf2AR2A"
      },
      "source": [
        "def drop_high_card_cols(x, thresh):\n",
        "  ### This function drops Categorical Columns ###\n",
        "  for col in df:\n",
        "    if df[col].dtype == 'object' and df[col].nunique > thresh:\n",
        "      df.drop(columns=col, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqetWDLtdYOU"
      },
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrBH1KtNdZ63"
      },
      "source": [
        "def newdf_oldcols(df, *cols):\n",
        "  ### This function returns a New Data Frame with Columns from an Existing Data Frame ###\n",
        "  new_df = df.loc[:, cols]\n",
        "  return new_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86odocnPdwn3"
      },
      "source": [
        "#Value Updates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_niVb0Kdzjo"
      },
      "source": [
        "def col_bool_maker(x):\n",
        "  ### This function creates a boolean value which indicates ... ###\n",
        "  if x == '':                                                                      # Fill in Strings\n",
        "    return 1\n",
        "  elif x == '':                                                                    # Fill in Strings\n",
        "    return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  #Function for Sub Lists\n",
        "def grouping(master_list, keyword):\n",
        "  ### This function returns a list of elements ###\n",
        "  ### containing a keyword from another list ###\n",
        "  return [x for x in master_list if keyword in x]"
      ],
      "metadata": {
        "id": "Oqco6AHCQXAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fill_col_nans(df, col, how):\n",
        "  ### This function fills a column's NaN values ###\n",
        "  ### For Mean Enter 'mean' in how; For Median etner 'median' in how ###\n",
        "\n",
        "  #If - Elif Statement to determine HOW\n",
        "  if how == 'mean':\n",
        "    #Find Column Mean & Fill NaN values\n",
        "    col_mean = df[col].mean()\n",
        "    df[col].fillna(value=col_mean, inplace=True)\n",
        "    return df\n",
        "\n",
        "  elif how == 'median':\n",
        "    #Find Column Median & Fill NaN values\n",
        "    col_median = df[col].median()\n",
        "    df[col].fillna(value=col_median, inplace=True)\n",
        "    return df\n",
        "\n",
        "  else:\n",
        "    #Print Exlpanation of HOW\n",
        "    print(\"You must enter 'mean' or 'median' for how\")"
      ],
      "metadata": {
        "id": "tfIaC2QhXtIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gY5CBnNAdaWf"
      },
      "source": [
        "# Maths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbHulPsbdbhP"
      },
      "source": [
        "def part_whole_perc(part, whole, symbol):\n",
        "  ### This function tells you what percent a value makes of its whole round to 3 decimal places###\n",
        "  ## x should be 'yes' to print with a % sign, or 'no' to return a float ##\n",
        "  percentage = float(part)/float(whole) * 100\n",
        "  percentage = round(percentage, 3)\n",
        "  if symbol =='yes'.lower():\n",
        "    print(f\"{percentage}%\")      \n",
        "  else:\n",
        "   return percentage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fahrenheit_to_celsius_converter(fahrenheit):\n",
        "  ### This function convers temperatures in fahrenheit to celsius ###\n",
        "  celsius = (fahrenheit - 32) * (5/9)\n",
        "  return celsius"
      ],
      "metadata": {
        "id": "Pv-AfR4AXmsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNu1VJE85bhr"
      },
      "source": [
        "#Statistical Models and Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZCGRJ8Q9NRR"
      },
      "source": [
        "Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ko0eIVr-9Wmk"
      },
      "source": [
        "def sigmoid_beta(x, beta_0, beta_1):\n",
        "  ## This function defines a sigmoid with coefficients  ##\n",
        "    exp = beta_0 + beta_1*x\n",
        "    return 1 / (1 + np.e**(-exp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKyV0neFVvJ8"
      },
      "source": [
        "##Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8_mAA0I9Iyk"
      },
      "source": [
        "### P_Val"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmBmUNjAeIVQ"
      },
      "source": [
        "# Pvalue & Alpha Analysis\n",
        "\n",
        "def pval_alpha05(pval, dependant_var, *args):\n",
        "  ### This function rejects or fails to reject the null hypothesis at a confidence level of .05 ###\n",
        "  if pval < .05:\n",
        "    print(f\"\"\"\n",
        "    At a signficance level of .05 and a Pvalue of {pval}: \n",
        "    we reject the null hypothesis, and conclude there is a relationship between {dependant_var} and {args}\n",
        "    \"\"\")\n",
        "  else: \n",
        "    print(f\"\"\"\n",
        "    At a signficance level of .05 and a Pvalue of {pval}: \n",
        "    we fail to reject the null hypothesis, and conclude there is no relationship between {dependant_var} and {args}\n",
        "    \"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LGS9F2G9Oav"
      },
      "source": [
        "### R Square"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYpOebzI5eZq"
      },
      "source": [
        "def rsquare_comparison(x,y, added_variable):\n",
        "  ### This function interprets the R-Square and Adj-Square Values of OLS models. ###\n",
        "  if x < y:\n",
        "    print(f\"The addition of {added_variable} improved our model's predictive ability.\")\n",
        "  elif x > y: \n",
        "    print(f\"The addition of {added_variable} diminished our model's predictive ability.\")\n",
        "  elif x == y:\n",
        "    print(f\"The addition of {added_variable} had no affect on our model's predictive ability.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8Z09XwZECHK"
      },
      "source": [
        "def variance_maker(x,y):\n",
        "  ### This function converts the R-Square & Adjusted R-Square values of OLS Models into Variance Percentages ###\n",
        "  x = round(x*100, 3)\n",
        "  y = round(y*100, 3)\n",
        "  change = abs(x-y)\n",
        "  print(f\"\"\"\n",
        "  Model 1 Variance: {x}%\n",
        "  Model 2 Adjusted Variance {y}%\n",
        "  Change in Variance: {change}%\n",
        "  \"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRpUpb-t9YCg"
      },
      "source": [
        "def calc_model_r2(model, X_group, y_group):\n",
        "  ### This Function returns the R Square Value for a Model using Train Test Split Data ###\n",
        "  return model.score(X_group, y_group)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be8Rcecx9QXf"
      },
      "source": [
        "###Mean Absolute Error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJYahgNoE8sM"
      },
      "source": [
        "def calc_baseline_mae(y_train):\n",
        "  ### This function returns a Baseline Mean Absolute Error (Mean of y_train) ###\n",
        "  \n",
        "  y_pred = [y_train.mean()] * len(y_train)                                        #Mean Equation\n",
        "\n",
        "  baseline_mae = mean_absolute_error(y_train, y_pred)                             #MAE Calculation\n",
        "  \n",
        "  print(f'''\n",
        "  Baseline MAE: {baseline_mae}                                                   \n",
        "  ''')\n",
        "\n",
        "  return baseline_mae            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q91JEFrR-EiV"
      },
      "source": [
        "def calc_model_mae(model_name, model, X_train, y_train, X_val, y_val):\n",
        "  ### This function returns the Mean Absolute Error of a Model ###\n",
        "\n",
        "  #Calculations\n",
        "  train_mae = mean_absolute_error(y_train, model.predict(X_train))\n",
        "  val_mae = mean_absolute_error(y_val, model.predict(X_val))\n",
        "\n",
        "  print(f'''\n",
        "  {model_name} Training MAE:  {train_mae}\n",
        "  {model_name} Validation MAE:  {val_mae}  \n",
        "  ''')\n",
        "\n",
        "  return train_mae, val_mae\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Accuracy Score"
      ],
      "metadata": {
        "id": "D_9_DmmGH2kT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def baseline_accuracy(y_train):\n",
        "  ### This function calculates a baseline accuracy ###\n",
        "  base_acc = y_train.value_counts(normalize=True).max()                           #Equation\n",
        "\n",
        "  print(f'Baseline Accuracy: {base_acc}')\n",
        "\n",
        "  return base_acc"
      ],
      "metadata": {
        "id": "Po9mCicxH_DR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def acc_score_trainval(model_name, model, X_train, y_train, X_val, y_val):\n",
        "  ###This function returns the accuracy score of a model for the ###\n",
        "  ### Train and Validation sets ###\n",
        "\n",
        "  #Calculations\n",
        "  train_score = model.score_(X_train, y_train)\n",
        "  val_score = model.score_(X_val, y_val)\n",
        "\n",
        "  print(f'''\n",
        "  {model_name} Training Accuracy:  {train_score}\n",
        "  {model_name} Validation Accuracy:  {val_score}  \n",
        "  ''')\n",
        "\n",
        "  return train_score, val_score"
      ],
      "metadata": {
        "id": "WYrXEIxiH53E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###.score"
      ],
      "metadata": {
        "id": "MJLJIkdTvUDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_model_score(model_name, model, X_train, y_train, X_val, y_val):\n",
        "  ###This function returns the training and validation scores of a model###\n",
        "\n",
        "  train_score = model.score(X_train, y_train)\n",
        "  val_score = model.score(X_val, y_val)\n",
        "\n",
        "  print(f'''\n",
        "  {model_name} Training Accuracy:  {train_score}\n",
        "  {model_name} Validation Accuracy:  {val_score}  \n",
        "  ''')\n",
        "\n",
        "  return train_score, val_score"
      ],
      "metadata": {
        "id": "YfnzyYnzvW5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ov4eGjBcVowy"
      },
      "source": [
        "###Dead"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TQlZnecVyP1"
      },
      "source": [
        "#Data Splitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmLQamPa-GKT"
      },
      "source": [
        "### THIS IS NOT A FUNCTION ###\n",
        "### For use with Below Functions ###\n",
        "\n",
        "# Target and Feature Creation\n",
        "target = # Insert String of Column Name #\n",
        "y = df[target]\n",
        "X = df.drop(columns=target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mj5Wklk7Wrkc"
      },
      "source": [
        "##Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3UWvg7gYEid"
      },
      "source": [
        "def train_test_split_target(df, target):\n",
        "  ## This function performs a random train test split 80/20##\n",
        "  ## This function drops using a target value ##\n",
        "  y = df[target]                                                                  #Target\n",
        "  X = df.drop(columns=target)                                                     #Features\n",
        "  from sklearn.model_selection import train_test_split                            #Import\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,        #Instatiate\n",
        "                                                    random_state=42)\n",
        "  return X_train, X_test, y_train, y_test                                         ### SAVE RETURN VARIABLES ### "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwbAcQ_tV0xn"
      },
      "source": [
        "def train_test_split_features(df, target, *args):\n",
        "  ## This function performs a random train test split 80/20##\n",
        "  ## This function drops using a list (*args) of features ##\n",
        "  features = [args] \n",
        "  y = df[target]                                                                  #Target\n",
        "  X = df.drop(columns=features)                                                   #Features\n",
        "  from sklearn.model_selection import train_test_split                            #Import\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,        #Instantiate\n",
        "                                                    random_state=42)\n",
        "  return X_train, X_test, y_train, y_test                                         ### SAVE RETURN VARIABLES ### "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UlzZvHyaqzX"
      },
      "source": [
        "def train_test_drop_comask(df, target, cutoff):\n",
        "  ## This function splits a data set into X and y Training and Test Sets ##\n",
        "\n",
        "  #Set X and y\n",
        "  y=df[target]\n",
        "  X=df.drop(columns=target)\n",
        "  \n",
        "  #Set Cut Off and mask\n",
        "  split_point = cutoff\n",
        "\n",
        "  mask = X.index < split_point  \n",
        "\n",
        "  #Create Train Test Sets\n",
        "  X_train, y_train = X.loc[mask], y.loc[mask]\n",
        "  X_test, y_test = X.loc[~mask], y.loc[~mask]\n",
        "\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train Test Val"
      ],
      "metadata": {
        "id": "QnKHkMrn69Wz"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASHjaCed7VJS"
      },
      "source": [
        "def train_test_val_drop_comask(df, target, cutoff_test, cutoff_val):\n",
        "  ## This function splits a data set into X and y Training, Test, and Validation Sets ##\n",
        "  \n",
        "  #Set X and y\n",
        "  y=df[target]\n",
        "  X=df.drop(columns=target)\n",
        "  \n",
        "  #Set Cut Offs\n",
        "  cutoff_test = cutoff_test\n",
        "  cutoff_val = cutoff_val\n",
        "  \n",
        "  #Set Test Mask\n",
        "  mask_test = X.index < cutoff_test\n",
        "\n",
        "  #Create Train Test Sets\n",
        "  X_train_def, y_train_def = X.loc[mask_test], y.loc[mask_test]\n",
        "  X_test, y_test = X.loc[~mask_test], y.loc[~mask_test]\n",
        "    \n",
        "  #Set Validation Mask\n",
        "  mask_val = X_train_def.index < cutoff_val\n",
        "\n",
        "  #Create Train Validation Sets\n",
        "  X_train, y_train = X_train_def.loc[mask_val], y_train_def.loc[mask_val]\n",
        "  X_val, y_val = X_train_def.loc[~mask_val], y_train_def.loc[~mask_val]\n",
        "\n",
        "  return X_train, X_test, X_val, y_train, y_test, y_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_val_validation(X_train, y_train, X_val, y_val, X_test, y_test):\n",
        "  ### This function prints a summary to verify split occurred accurately and without overlap ###\n",
        "  print(f'''\n",
        "Training Set\n",
        "X_train Range: {X_train.index.min()} to {X_train.index.max()}\n",
        "X_train Shape: {X_train.shape}\n",
        "y_train Range: {y_train.index.min()} to {y_train.index.max()}\n",
        "y_train Shape: {y_train.shape}\n",
        "\n",
        "---\n",
        "\n",
        "Validation Set\n",
        "X_val Range: {X_val.index.min()} to {X_val.index.max()}\n",
        "X_val Shape: {X_val.shape}\n",
        "y_val Range: {y_val.index.min()} to {y_val.index.max()}\n",
        "y_val Shape: {y_val.shape}\n",
        "\n",
        "---\n",
        "\n",
        "Test Set\n",
        "X_test Range: {X_test.index.min()} to {X_test.index.max()}\n",
        "X_test Shape: {X_test.shape}\n",
        "y_test Range: {y_test.index.min()} to {y_test.index.max()}\n",
        "y_test Shape: {y_test.shape}\n",
        "\n",
        "---\n",
        "\n",
        "Sum of Splits Length: {len(y_train) + len(y_val) + len(y_test)}\n",
        "Data Frane Length: {len(NSW_wildfires)}\n",
        "Splits and Data Frame have the same length? {\n",
        "    (len(y_train) + len(y_val) + len(y_test)) == len(NSW_wildfires)}\n",
        "\n",
        "''') "
      ],
      "metadata": {
        "id": "huueg1db6THa"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjU85cE4E5BV"
      },
      "source": [
        "###Baselines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIpzM78yFcNc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}